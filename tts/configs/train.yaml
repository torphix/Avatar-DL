seed: 1234
split_size: [0.98, 0.02]
dist_config:
  dist_backend: "nccl"
  dist_url: "tcp://localhost:80000"
  world_size: 1
path:
  ckpt_path: "./trained_models/ckpt/"
  log_path: "./output/log/lex"
  result_path: "./output/result/lex"
optimizer:
  lr: 1.0e-5
  betas: [0.9, 0.98]
  eps: 0.000000001
  weight_decay: 0.0
dataloader:
  batch_size: 8
  shuffle: True
  pin_memory: True
  num_workers: 4
step:
  total_step: 5001
  log_step: 100
  synth_step: 1000
  val_step: 1000
  save_step: 20000
  ctc_step: 1000
aligner:
  helper_type: "dga" # ["dga", "ctc", "none"]
  ctc_weight_start: 1.0
  ctc_weight_end: 1.0
  guided_sigma: 0.4
  guided_lambda: 1.0
  guided_weight: 1.0
trainer:
  devices: 1
  max_epochs: 3
  min_epochs: 3
  auto_lr_find: False
  # auto_scale_batch_size: "binsearch"
  check_val_every_n_epoch: 1
  accelerator: "gpu"
  # Load checkpoint from here
  gradient_clip_val: 1
  gradient_clip_algorithm: "value"
  accumulate_grad_batches: 1
  # Provide one or the other
  checkpoint_path: 
  log_every_n_steps: 10